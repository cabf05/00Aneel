import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
import pydeck as pdk
import requests
import streamlit as st
from requests.adapters import HTTPAdapter
from st_aggrid import AgGrid, GridOptionsBuilder
from st_aggrid.shared import GridUpdateMode
from urllib3.util.retry import Retry

st.set_page_config(layout=â€œwideâ€, page_title=â€œBrazil Energy Intelligenceâ€)

st.title(â€œâš¡ Brazil Energy Intelligence Dashboard - Usinas & GDâ€)

# =====================================================

# CONFIGURAÃ‡Ã•ES

# =====================================================

BASE_URL = â€œhttps://dadosabertos.aneel.gov.br/api/3/action/datastore_searchâ€

RES_USINAS  = â€œ11ec447d-698d-4ab8-977f-b424d5deee6aâ€
RES_GD_INFO = â€œb1bd71e7-d0ad-4214-9053-cbd58e9564a7â€
RES_GD_FOTO = â€œ49fa9ca0-f609-4ae3-a6f7-b97bd0945a3aâ€

# Coluna UF de cada recurso

UF_COL_USINAS  = â€œSigUFPrincipalâ€
UF_COL_GD_INFO = â€œSigUFâ€

# GD Foto nÃ£o tem coluna UF (Ã© dados tÃ©cnicos), serÃ¡ buscada completa e filtrada via merge

ESTADOS_BR = sorted([
â€œACâ€,â€œALâ€,â€œAMâ€,â€œAPâ€,â€œBAâ€,â€œCEâ€,â€œDFâ€,â€œESâ€,â€œGOâ€,
â€œMAâ€,â€œMGâ€,â€œMSâ€,â€œMTâ€,â€œPAâ€,â€œPBâ€,â€œPEâ€,â€œPIâ€,â€œPRâ€,
â€œRJâ€,â€œRNâ€,â€œROâ€,â€œRRâ€,â€œRSâ€,â€œSCâ€,â€œSEâ€,â€œSPâ€,â€œTOâ€
])

# =====================================================

# SESSÃƒO HTTP COM RETRY

# =====================================================

def make_session():
session = requests.Session()
retry = Retry(
total=3,
backoff_factor=1,
status_forcelist=[429, 500, 502, 503, 504],
allowed_methods=[â€œGETâ€]
)
adapter = HTTPAdapter(max_retries=retry)
session.mount(â€œhttps://â€, adapter)
session.mount(â€œhttp://â€, adapter)
return session

# =====================================================

# FUNÃ‡ÃƒO BASE DE PAGINAÃ‡ÃƒO (SEM st.*, THREAD-SAFE)

# =====================================================

def fetch_all_pages(resource_id, filters: dict = None, limit_per_page: int = 1000):
â€œâ€â€
Busca todas as pÃ¡ginas de um recurso ANEEL.
ParÃ¢metro `filters` (dict): campo â†’ valor exato para filtrar na API.
â€œâ€â€
session = make_session()
offset = 0
total = None
all_records = []

```
while True:
    params = {
        "resource_id": resource_id,
        "limit": limit_per_page,
        "offset": offset,
    }
    if filters:
        params["filters"] = json.dumps(filters)

    try:
        response = session.get(BASE_URL, params=params, timeout=60)
        data = response.json()

        if not data.get("success", False):
            print(f"[ERRO] API retornou success=False para {resource_id[-8:]} offset={offset}")
            break

        result = data["result"]

        if total is None:
            total = result.get("total", 0)
            print(f"[INFO] {resource_id[-8:]} | filtro={filters} | total={total}")

        records = result.get("records", [])
        if not records:
            break

        all_records.extend(records)
        offset += limit_per_page

        if offset >= total:
            break

        time.sleep(0.1)

    except Exception as e:
        print(f"[AVISO] {resource_id[-8:]} offset={offset} erro: {e}")
        break

return pd.DataFrame(all_records)
```

# =====================================================

# FETCH FILTRADO POR UF (UMA UF POR CHAMADA)

# =====================================================

def fetch_uf(resource_id: str, uf_column: str, uf: str) -> pd.DataFrame:
return fetch_all_pages(resource_id, filters={uf_column: uf})

# =====================================================

# CARREGAMENTO RAW COM CACHE POR SELEÃ‡ÃƒO DE UFs

# Chave do cache = tupla ordenada de UFs selecionadas

# =====================================================

@st.cache_data(show_spinner=False)
def carregar_raw(ufs_tuple: tuple) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
â€œâ€â€
Carrega dados brutos das 3 APIs em paralelo.

```
- Se todas as UFs estÃ£o selecionadas (ou nenhuma): busca global sem filtro (3 threads).
- SenÃ£o: busca por UF em paralelo para usinas e gd_info.
  GD Foto nÃ£o possui coluna UF; Ã© buscada globalmente e filtrada via merge posterior.
"""
ufs = list(ufs_tuple)
todas = set(ufs) >= set(ESTADOS_BR)

if todas:
    # ---- MODO GLOBAL: 3 recursos em paralelo, sem filtro ----
    with ThreadPoolExecutor(max_workers=3) as ex:
        f_us   = ex.submit(fetch_all_pages, RES_USINAS)
        f_gd   = ex.submit(fetch_all_pages, RES_GD_INFO)
        f_foto = ex.submit(fetch_all_pages, RES_GD_FOTO)

    return f_us.result(), f_gd.result(), f_foto.result()

else:
    # ---- MODO POR UF: uma thread por (recurso Ã— UF) ----
    # Limite de workers para nÃ£o sobrecarregar a API
    max_workers = min(len(ufs) * 2 + 1, 12)

    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        # Submete uma tarefa por (recurso, UF)
        fut_usinas  = {ex.submit(fetch_uf, RES_USINAS,  UF_COL_USINAS,  uf): uf for uf in ufs}
        fut_gd_info = {ex.submit(fetch_uf, RES_GD_INFO, UF_COL_GD_INFO, uf): uf for uf in ufs}
        # GD Foto: busca global (sem UF) â€” serÃ¡ filtrada apÃ³s o merge com GD Info
        fut_foto = ex.submit(fetch_all_pages, RES_GD_FOTO)

        # Coleta resultados de usinas
        parts_usinas = []
        for fut in as_completed(fut_usinas):
            try:
                parts_usinas.append(fut.result())
            except Exception as e:
                print(f"[ERRO] Usinas UF={fut_usinas[fut]}: {e}")

        # Coleta resultados de gd_info
        parts_gd = []
        for fut in as_completed(fut_gd_info):
            try:
                parts_gd.append(fut.result())
            except Exception as e:
                print(f"[ERRO] GD Info UF={fut_gd_info[fut]}: {e}")

        df_foto = fut_foto.result()

    df_usinas = pd.concat(parts_usinas, ignore_index=True) if parts_usinas else pd.DataFrame()
    df_gd     = pd.concat(parts_gd,     ignore_index=True) if parts_gd     else pd.DataFrame()

    return df_usinas, df_gd, df_foto
```

# =====================================================

# TRANSFORMAÃ‡Ã•ES E UNIFICAÃ‡ÃƒO

# =====================================================

@st.cache_data(show_spinner=False)
def carregar_dados_unificados(ufs_tuple: tuple) -> pd.DataFrame:
df_usinas, df_gd, df_gd_tech = carregar_raw(ufs_tuple)

```
# ----- USINAS -----
if not df_usinas.empty:
    df_usinas["Potencia MW"] = pd.to_numeric(
        df_usinas.get("MdaPotenciaOutorgadaKw", pd.Series(dtype=str))
            .astype(str).str.replace(".", "", regex=False).str.replace(",", ".", regex=False),
        errors="coerce"
    ) / 1000

    df_usinas["Lat"] = pd.to_numeric(
        df_usinas.get("NumCoordNEmpreendimento", pd.Series(dtype=str))
            .astype(str).str.replace(",", "."), errors="coerce"
    )
    df_usinas["Lon"] = pd.to_numeric(
        df_usinas.get("NumCoordEEmpreendimento", pd.Series(dtype=str))
            .astype(str).str.replace(",", "."), errors="coerce"
    )

    if "DscFaseUsina" in df_usinas.columns:
        df_usinas = df_usinas[df_usinas["DscFaseUsina"] == "OperaÃ§Ã£o"]

    df_usinas = df_usinas.rename(columns={
        "CodCEG":               "Codigo",
        "NomEmpreendimento":    "Nome",
        "SigUFPrincipal":       "UF",
        "DscOrigemCombustivel": "Fonte",
    })
    df_usinas["Categoria"] = "Usina (GeraÃ§Ã£o Centralizada)"

# ----- GERAÃ‡ÃƒO DISTRIBUÃDA -----
if not df_gd.empty:
    if not df_gd_tech.empty:
        df_gd = df_gd.merge(
            df_gd_tech[["CodGeracaoDistribuida", "NomFabricanteModulo", "NomFabricanteInversor"]],
            left_on="CodEmpreendimento",
            right_on="CodGeracaoDistribuida",
            how="left"
        )

    df_gd["Potencia MW"] = pd.to_numeric(
        df_gd.get("MdaPotenciaInstaladaKW", pd.Series(dtype=str))
            .astype(str).str.replace(".", "", regex=False).str.replace(",", ".", regex=False),
        errors="coerce"
    ) / 1000

    df_gd["Lat"] = pd.to_numeric(
        df_gd.get("NumCoordNEmpreendimento", pd.Series(dtype=str))
            .astype(str).str.replace(",", "."), errors="coerce"
    )
    df_gd["Lon"] = pd.to_numeric(
        df_gd.get("NumCoordEEmpreendimento", pd.Series(dtype=str))
            .astype(str).str.replace(",", "."), errors="coerce"
    )

    df_gd = df_gd.rename(columns={
        "CodEmpreendimento":        "Codigo",
        "NomTitularEmpreendimento": "Nome",
        "SigUF":                    "UF",
        "DscFonteGeracao":          "Fonte",
    })
    df_gd["Categoria"] = "GeraÃ§Ã£o DistribuÃ­da"

# ----- MERGE FINAL -----
cols_padrao = ["Codigo", "Nome", "Categoria", "UF", "Fonte", "Potencia MW", "Lat", "Lon"]

for col in ["NomFabricanteModulo", "NomFabricanteInversor"]:
    if col not in df_gd.columns:
        df_gd[col] = "-"

cols_gd = cols_padrao + ["NomFabricanteModulo", "NomFabricanteInversor"]

df_final = pd.concat([
    df_usinas[cols_padrao] if not df_usinas.empty else pd.DataFrame(columns=cols_padrao),
    df_gd[cols_gd]         if not df_gd.empty    else pd.DataFrame(columns=cols_gd),
], ignore_index=True)

return df_final.dropna(subset=["Lat", "Lon"]).reset_index(drop=True)
```

# =====================================================

# SELEÃ‡ÃƒO DE ESTADOS â€” PRIMEIRO PASSO DA UI

# =====================================================

st.sidebar.header(â€œğŸ—ºï¸ SeleÃ§Ã£o de Estadosâ€)

selecionar_todos = st.sidebar.checkbox(â€œSelecionar todos os estadosâ€, value=False)

if selecionar_todos:
ufs_escolhidas = ESTADOS_BR
st.sidebar.caption(fâ€Todos os {len(ESTADOS_BR)} estados selecionados.â€)
else:
ufs_escolhidas = st.sidebar.multiselect(
â€œEstados (UF)â€,
options=ESTADOS_BR,
default=[â€œSPâ€, â€œRJâ€],
help=â€œSelecione um ou mais estados. O sistema buscarÃ¡ os dados em paralelo apenas para os estados escolhidos.â€
)

if not ufs_escolhidas:
st.warning(â€œâš ï¸ Selecione ao menos um estado na barra lateral para carregar os dados.â€)
st.stop()

# BotÃ£o de carga â€” evita busca automÃ¡tica a cada interaÃ§Ã£o

carregar = st.sidebar.button(â€œğŸ”„ Carregar / Atualizar Dadosâ€, type=â€œprimaryâ€, use_container_width=True)

# Controla se jÃ¡ hÃ¡ dados na sessÃ£o para os estados atuais

chave_cache = tuple(sorted(ufs_escolhidas))

if â€œchave_atualâ€ not in st.session_state or st.session_state[â€œchave_atualâ€] != chave_cache:
# Nova seleÃ§Ã£o ainda nÃ£o carregada â€” forÃ§a o usuÃ¡rio a clicar no botÃ£o
if not carregar:
estados_str = â€œ, â€œ.join(ufs_escolhidas) if len(ufs_escolhidas) <= 5 else fâ€{len(ufs_escolhidas)} estadosâ€
st.info(fâ€ğŸ“‹ Estados selecionados: **{estados_str}**. Clique em **Carregar / Atualizar Dados** para buscar.â€)
st.stop()

# Efetua a carga (ou usa cache se jÃ¡ foi feita antes para essa combinaÃ§Ã£o)

if carregar or â€œchave_atualâ€ in st.session_state:
st.session_state[â€œchave_atualâ€] = chave_cache

modo = â€œtodos os estadosâ€ if selecionar_todos else fâ€{len(ufs_escolhidas)} estado(s): {â€™, â€™.join(ufs_escolhidas)}â€

with st.spinner(fâ€â³ Buscando dados para {modo} em paraleloâ€¦â€):
df = carregar_dados_unificados(chave_cache)

if df.empty:
st.error(â€œNenhum dado retornado para os estados selecionados. Tente novamente ou selecione outros estados.â€)
st.stop()

st.sidebar.success(fâ€âœ… {len(df):,} instalaÃ§Ãµes carregadas.â€)
st.sidebar.markdown(â€â€”â€)

# =====================================================

# FILTROS ADICIONAIS (pÃ³s-carga)

# =====================================================

st.sidebar.header(â€œğŸ” Filtrosâ€)

categorias = st.sidebar.multiselect(
â€œCategoriaâ€,
sorted(df[â€œCategoriaâ€].dropna().unique()),
default=sorted(df[â€œCategoriaâ€].dropna().unique())
)
fontes = st.sidebar.multiselect(â€œFonte de Energiaâ€, sorted(df[â€œFonteâ€].dropna().unique()))

pot_max_val = float(df[â€œPotencia MWâ€].max()) if df[â€œPotencia MWâ€].max() > 0 else 1.0
pot_min, pot_max = st.sidebar.slider(
â€œCapacidade (MW)â€,
0.0, pot_max_val,
(0.0, pot_max_val)
)

# Aplica filtros

df_filtrado = df.copy()
if categorias: df_filtrado = df_filtrado[df_filtrado[â€œCategoriaâ€].isin(categorias)]
if fontes:     df_filtrado = df_filtrado[df_filtrado[â€œFonteâ€].isin(fontes)]
df_filtrado = df_filtrado[
(df_filtrado[â€œPotencia MWâ€] >= pot_min) &
(df_filtrado[â€œPotencia MWâ€] <= pot_max)
]

# =====================================================

# MÃ‰TRICAS

# =====================================================

col1, col2, col3, col4 = st.columns(4)
col1.metric(â€œTotal de InstalaÃ§Ãµesâ€,   fâ€{len(df_filtrado):,}â€)
col2.metric(â€œCapacidade Total (MW)â€,  fâ€{df_filtrado[â€˜Potencia MWâ€™].sum():,.2f}â€)
col3.metric(â€œEstadosâ€,                df_filtrado[â€œUFâ€].nunique())
col4.metric(â€œFontes distintasâ€,       df_filtrado[â€œFonteâ€].nunique())

st.markdown(â€â€”â€)

# =====================================================

# MAPA

# =====================================================

st.subheader(â€œğŸ—ºï¸ VisÃ£o Geoespacialâ€)

map_data = df_filtrado.copy()
center_lat = map_data[â€œLatâ€].mean() if not map_data.empty else -14.2350
center_lon = map_data[â€œLonâ€].mean() if not map_data.empty else -51.9253
zoom_level = 7 if len(ufs_escolhidas) == 1 else (5 if len(ufs_escolhidas) <= 5 else 4)

map_data[â€œmap_radiusâ€] = map_data[â€œPotencia MWâ€].apply(lambda x: max(x * 500, 2000))

if len(map_data) > 3000:
layer = pdk.Layer(
â€œHexagonLayerâ€, data=map_data, get_position=â€[Lon, Lat]â€,
radius=30000, elevation_scale=50, pickable=True, extruded=True,
)
tooltip_html = {â€œhtmlâ€: â€œ<b>Agrupamento</b><br/>InstalaÃ§Ãµes na Ã¡rea: <b>{elevationValue}</b>â€}
else:
layer = pdk.Layer(
â€œScatterplotLayerâ€, data=map_data, get_position=â€[Lon, Lat]â€,
get_radius=â€œmap_radiusâ€, get_fill_color=[0, 110, 255, 180], pickable=True,
)
tooltip_html = {
â€œhtmlâ€: â€œ<b>{Nome}</b><br/>Tipo: {Categoria}<br/>â€
â€œCapacidade: {Potencia MW} MW<br/>Estado: {UF}<br/>Fonte: {Fonte}â€
}

st.pydeck_chart(pdk.Deck(
layers=[layer],
initial_view_state=pdk.ViewState(latitude=center_lat, longitude=center_lon, zoom=zoom_level),
map_style=pdk.map_styles.LIGHT,
tooltip=tooltip_html
))

st.markdown(â€â€”â€)

# =====================================================

# TABELA

# =====================================================

st.subheader(â€œğŸ“‹ Base de Dados Completaâ€)

df_exibicao = (
df_filtrado
.drop(columns=[â€œmap_radiusâ€], errors=â€œignoreâ€)
.sort_values(â€œPotencia MWâ€, ascending=False)
)

gb = GridOptionsBuilder.from_dataframe(df_exibicao)
gb.configure_default_column(filter=True, sortable=True, resizable=True, floatingFilter=True)
gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=50)
gb.configure_selection(â€œsingleâ€, use_checkbox=True)

AgGrid(
df_exibicao,
gridOptions=gb.build(),
update_mode=GridUpdateMode.NO_UPDATE,
theme=â€œstreamlitâ€,
height=500
)

# =====================================================

# DOWNLOAD

# =====================================================

csv = df_exibicao.to_csv(index=False).encode(â€œutf-8â€)
st.download_button(
â€œâ¬‡ï¸ Baixar Dados Filtrados (CSV)â€,
csv,
â€œdados_energia_brasil.csvâ€,
â€œtext/csvâ€
)
